{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6de3781",
   "metadata": {},
   "source": [
    "### LangChain V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae69c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.3\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee531a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4e9b4",
   "metadata": {},
   "source": [
    "### GEN AI APPLICATION USING AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469853b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm doing great, thank you for asking. How can I assist you today?\" additional_kwargs={'reasoning_content': \"We need to respond according to policies. It's a casual greeting. Should respond friendly.\"} response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 77, 'total_tokens': 122, 'completion_time': 0.094735563, 'completion_tokens_details': {'reasoning_tokens': 18}, 'prompt_time': 0.003707712, 'prompt_tokens_details': None, 'queue_time': 0.049441938, 'total_time': 0.098443275}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_d29d1d1418', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bb641-dd03-7b42-9f94-175c8d7b6bab-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 77, 'output_tokens': 45, 'total_tokens': 122, 'output_token_details': {'reasoning': 18}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"openai/gpt-oss-120b\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf4d8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm doing great, thanks for asking. How can I help you today?\" additional_kwargs={'reasoning_content': 'We need to respond. The system says we are ChatGPT, with knowledge cutoff 2024-06. The user says \"Hello, how are you?\" We should respond friendly. No special instructions. So answer accordingly.'} response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 77, 'total_tokens': 149, 'completion_time': 0.15789115, 'completion_tokens_details': {'reasoning_tokens': 46}, 'prompt_time': 0.003896958, 'prompt_tokens_details': None, 'queue_time': 0.049203422, 'total_time': 0.161788108}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_626f3fc5e0', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bb642-a3a9-79b0-8cf6-ae31f378509e-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 77, 'output_tokens': 72, 'total_tokens': 149, 'output_token_details': {'reasoning': 46}}\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "response = model.invoke(\"Hello, how are you?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c997fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
